# -*- coding: utf-8 -*-
"""_Mouse_Labeling_Avaneesh

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zD5IdaChOOXssdEyPQuXhCrsDd4SYoYB
"""

#(this will take a few minutes to install all the dependences!)

!pip install deeplabcut

#Importing Libraries
import cv2
import numpy as np
from scipy import signal
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

#GUIs don't work on the cloud, so label your data locally on your computer! This will suppress the GUI support
import os
os.environ["DLClight"]="True"

import deeplabcut

##Parameters You can Adjust

r = 10 ##Sensitivity for whether the nose and other part is touching
nose1_color = [255,0,0] #Red
rear1_color = [0,255,0] #Green
tail1_color = [0,0,255] #Blue
nose2_color = [255,91,71] #Orange
rear2_color = [219,48,130] #Majenta
tail2_color = [0,255,255] #Cyan
thr = 0.3 ##Threshold for Low-Pass, Lower to smoothen
pthr = 0.9

##Given the 2 coordiantes and 2 radii, this block checks too see if it overlaps
def isOverlap(x,y,x1,y1,r,r1):
  d = np.sqrt((x-x1)**2 + (y-y1)**2)
  if((d<np.abs(r-r1)) or (d>(r+r1))):
    return True
  else:
    return False

def lowPassFiltering(thr,arr): #ButterPass_LowPass Filter
  #Default Order
  n = 1
  Fs = 1
  #Constructing the filter
  nyquist_freq = Fs/2
  Wn = thr/nyquist_freq
  b,a = signal.butter(n,thr,'low',analog = False,output = 'ba') #lowpass butterworth filter using threshold
  arrfilt = signal.filtfilt(b,a,arr,0) #zerophase filter using coefficients
  return arrfilt

def getData(csv_file,thr):
  data = np.loadtxt(csv_file, delimiter=',', skiprows=3,usecols=(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18))
  ##Arrays are given by columns of x,y,probability
  #Apply Low-Pass
  n1 = [lowPassFiltering(thr,data[:,0]),lowPassFiltering(thr,data[:,1]),data[:,2]] 
  r1 = [lowPassFiltering(thr,data[:,3]),lowPassFiltering(thr,data[:,4]),data[:,5]]
  t1 = [lowPassFiltering(thr,data[:,6]),lowPassFiltering(thr,data[:,7]),data[:,8]] 
  n2 = [lowPassFiltering(thr,data[:,9]),lowPassFiltering(thr,data[:,10]),data[:,11]]
  r2 = [lowPassFiltering(thr,data[:,12]),lowPassFiltering(thr,data[:,13]),data[:,14]] 
  t2 = [lowPassFiltering(thr,data[:,15]),lowPassFiltering(thr,data[:,16]),data[:,17]]
  return n1,r1,t1,n2,r2,t2

def videoandmatlabfunction(vpath,n1,r1,t1,n2,r2,t2):
  cap = cv2.VideoCapture(vpath)
  vlength = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
  outputVideo = 'Labeled_.avi'
  outputData = 'Labeled_.mat'
  annotated = 'Annotated_.mat'
  outcap = cv2.VideoWriter(outputVideo,cv2.VideoWriter_fourcc('M','J','P','G'), 20, (width,height))

  i = 0
  ##Vectors for Nose2Nose,Nose2Rear,Nose2Tail
  n1_n2 =np.zeros((vlength,1),dtype = int)
  n1_r2 =np.zeros((vlength,1),dtype = int)
  n1_t2 =np.zeros((vlength,1),dtype = int)
  n2_r1 =np.zeros((vlength,1),dtype = int)
  n2_t1 =np.zeros((vlength,1),dtype = int)


  while(cap.isOpened()):
    if (i%1000 ==0):
        print(str((i*100)/vlength)+'% Frames Done')
    
    ret,frame = cap.read()

    if(ret==True):
      pn1 = n1[2][i]
      pt1 = t1[2][i]
      pr1 = r1[2][i]
      pn2 = n2[2][i]
      pt2 = t2[2][i]
      pr2 = r2[2][i]
      if(pn1>pthr):
        cv2.circle(frame,(int(n1[0][i]),int(n1[1][i])), r, nose1_color,2)
        if(pn2>pthr):
          cv2.circle(frame,(int(n2[0][i]),int(n2[1][i])), r, nose2_color,2)
          if(isOverlap(int(n1[0][i]),int(n1[1][i]),int(n2[0][i]),int(n2[1][i]),r,r)):
              n1_n2[i] = 1
        if(pr2>pthr): 
          cv2.circle(frame,(int(r2[0][i]),int(r2[1][i])), r, rear2_color,2)
          if(isOverlap(int(n1[0][i]),int(n1[1][i]),int(r2[0][i]),int(r2[1][i]),r,r)):
            n1_r2[i] = 1
        if(pt2>pthr):
          cv2.circle(frame,(int(t2[0][i]),int(t2[1][i])), r, tail2_color,2)
          if(isOverlap(int(n1[0][i]),int(n1[1][i]),int(t2[0][i]),int(t2[1][i]),r,r)):
            n1_t2[i] = 1
      if(pn2>pthr):
        if(pr1>pthr):
          cv2.circle(frame,(int(r1[0][i]),int(r1[1][i])), r, rear1_color,2)
          if(isOverlap(int(n2[0][i]),int(n2[1][i]),int(r1[0][i]),int(r1[1][i]),r,r)):
            n2_r1[i] = 1
        if(pt1>pthr):
          cv2.circle(frame,(int(t1[0][i]),int(t1[1][i])), r, tail1_color,2)
          if(isOverlap(int(n2[0][i]),int(n2[1][i]),int(t1[0][i]),int(t1[1][i]),r,r)):
            n2_t1[i] = 1

      outcap.write(frame)
      i = i+1
    else:
      break

    
  arr = np.column_stack((n1,r1,t1,n2,r2,t2))
  scipy.io.savemat(outputData, mdict={'arr': arr})
  arr1 = np.column_stack((n1_n2,n1_r2,n1_t2,n2_r1,n2_t1))
  scipy.io.savemat(annotated, mdict={'arr1': arr1})
  outcap.release()
  cap.release()
  cv2.destroyAllWindows()

#Setup your project variables:
ProjectFolderName = 'Sampled-ppzhao-2020-03-14'
VideoType = 'avi' 

videofile_path = '/content/drive/My Drive/'+ProjectFolderName+'/videos/' #Don't edit this, this is where DeepLab's Functions demands the directory to be
videofile_path1 = ['/content/drive/My Drive/'+ProjectFolderName+'/videos/'] #Don't edit this, this is where DeepLab's Functions demands the directory to be

#Edit this
directory_video = '/content/drive/My Drive/161soc' #Enter the list of videos or folder to analyze.

#This creates a path variable that links to your google drive copy
#No need to edit this, as you set it up before: 
path_config_file = '/content/drive/My Drive/'+ProjectFolderName+'/config.yaml'

import scipy.io
from google.colab import files
import os
import shutil 

filelist = os.listdir(directory_video)

for infile in sorted(filelist):
  sample_cap = cv2.VideoCapture(directory_video + '/' +str(infile))
  (width,height)=(int(sample_cap.get(3)),int(sample_cap.get(4)))
  
fullVideo = 'Unlabeled_Video.avi' #Name for Unlabeled Combined Video
cap1 = cv2.VideoWriter(fullVideo,cv2.VideoWriter_fourcc('M','J','P','G'), 20,(width,height))
for infile in sorted(filelist, key=lambda x: int("".join([i for i in x if i.isdigit()]))): 
  print ('Combining:'+directory_video + '/' +str(infile))
  cap = cv2.VideoCapture(directory_video + '/' +str(infile))
  while(cap.isOpened()):
    ret,frame = cap.read()
    if(ret == True):
      cap1.write(frame)
    else:
      break
  cap.release()
  
cap1.release()

shutil.move(fullVideo, videofile_path) #Moves the unlabeled video to the deeplabdirectory
print('Moved File to DeepLabCuts Directory')

##This will analyze the videos from the project's DeepLearning Model and use DeepLabCut's Median Filter.
deeplabcut.analyze_videos(path_config_file,videofile_path1, videotype=VideoType)
deeplabcut.filterpredictions(path_config_file,videofile_path1, videotype=VideoType)
print('Analyzed and Filtered using DeepLabCuts Models')

#Gets the Raw-Filtered Data After applying a Low-Pass Butterworth
n1,r1,t1,n2,r2,t2 = getData('Unlabeled_Video'+'DLC_resnet101_SampledMar14shuffle1_200000filtered.csv',thr)
print('Applied LowPass Filtering From DeepLabCut Data')


videoandmatlabfunction(fullVideo,n1,r1,t1,n2,r2,t2) ##Should Spitout the Labeled Video and Matlab Files
print('Labeled Video, RawPosition MatlabFile and Annonatation Matlabfile are ready for download!')
cv2.destroyAllWindows()